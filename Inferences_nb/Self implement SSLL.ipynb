{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Self implement SSLL.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyM4Av5vdtTGWDB30fnFu9rm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lbzl0yYDDIlJ","executionInfo":{"status":"ok","timestamp":1622291893028,"user_tz":-330,"elapsed":4150,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"07b67543-ad51-4c1c-b653-cadabf9d17cf"},"source":["!pip install kornia"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting kornia\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/f4/a47657770c423ad1e1d41295fd030442cc7e4987fe05936b0423b9d982d5/kornia-0.5.2-py2.py3-none-any.whl (279kB)\n","\r\u001b[K     |█▏                              | 10kB 16.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 30kB 10.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████                         | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 81kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 133kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 143kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 153kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 163kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 174kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 184kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 194kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 204kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 215kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 225kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 235kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 245kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 256kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 266kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 276kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from kornia) (1.19.5)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from kornia) (1.8.1+cu101)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->kornia) (3.7.4.3)\n","Installing collected packages: kornia\n","Successfully installed kornia-0.5.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sj2VpxtaROu4","executionInfo":{"status":"ok","timestamp":1622032639664,"user_tz":-330,"elapsed":60351,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"2ba998a8-0587-4e6d-b2ba-485acc23a4e6"},"source":["!pip install torchlars"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torchlars\n","  Downloading https://files.pythonhosted.org/packages/f5/12/633c1822dc87d72ad2a80ba40706c7a77056c68d6211351313ff0e96bda0/torchlars-0.1.2.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchlars) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->torchlars) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchlars) (3.7.4.3)\n","Building wheels for collected packages: torchlars\n","  Building wheel for torchlars (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for torchlars\u001b[0m\n","\u001b[?25h  Running setup.py clean for torchlars\n","Failed to build torchlars\n","Installing collected packages: torchlars\n","    Running setup.py install for torchlars ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-2_r991_p/torchlars/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-2_r991_p/torchlars/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-jkva1rvz/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DyMH1DMWGsS4","executionInfo":{"status":"ok","timestamp":1622291897034,"user_tz":-330,"elapsed":4014,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["import numpy as np\n","import copy\n","import time\n","import random\n","from functools import wraps\n","import matplotlib.pyplot as plt\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","\n","from torchvision.datasets import CIFAR10\n","from torchvision import transforms\n","from torchvision.models import squeezenet\n","from kornia import augmentation as augs\n","from kornia import filters\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XHzrXnN1DCnw","executionInfo":{"status":"ok","timestamp":1622102428910,"user_tz":-330,"elapsed":2554,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"adc66ba7-07fa-42b5-c445-39a936dae0f2"},"source":["train_data=CIFAR10(root=\"/content/images\", train=True, download=True, transform=transforms.ToTensor())\n","test_data=CIFAR10(root=\"/content/images\", train=False, download=True, transform=transforms.ToTensor())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O967ZQqervRH","executionInfo":{"status":"ok","timestamp":1622102431771,"user_tz":-330,"elapsed":427,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"7b733432-b04c-4d3a-c26f-e591b3f5f0bf"},"source":["def sort_indices(data, nclass = 2):\n","  full_labels = np.array(data.targets)\n","  labels = [i for i in range(10)]\n","  indices = []\n","  for label in labels:\n","    indice = (full_labels == label).nonzero()[0]\n","    indices.append(indice)\n","\n","  total_indices=np.array([], dtype=np.int16)\n","  for i in range(nclass):\n","    #print(indices[i])\n","    total_indices = np.append(total_indices, indices[i]) \n","  print(total_indices.shape)\n","  return total_indices\n","\n","#test_in = sort_indices(test_data, 2)\n","train_indices = sort_indices(train_data, 2)\n","test_indices = sort_indices(test_data, 2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10000,)\n","(2000,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oCUBbV0GEJdR","executionInfo":{"status":"ok","timestamp":1622102439787,"user_tz":-330,"elapsed":442,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"9ce7d7d8-e77b-4f69-c855-f1b1a0956e1e"},"source":["val_indices = np.append(train_indices[:500], train_indices[-500:])\n","train_indices = train_indices[500:-500]\n","train_indices.shape, val_indices.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((9000,), (1000,))"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"boijSQ549qJx","executionInfo":{"status":"ok","timestamp":1622102441613,"user_tz":-330,"elapsed":13,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"93ba8dd4-4819-45c4-e219-455a75de9806"},"source":["ratio = 0.6\n","train1_indices = np.append(train_indices[:int(4500*ratio)], train_indices[4500:int(4500*(2-ratio))])\n","train2_indices = np.append(train_indices[int(4500*(2-ratio)):], train_indices[int(4500*ratio):4500])\n","train1_indices.shape, train2_indices.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4500,), (4500,))"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y65kNV2ATUs","executionInfo":{"status":"ok","timestamp":1622102443812,"user_tz":-330,"elapsed":386,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"4b1d0e00-d3bb-4617-87cc-a1a5c2f316e5"},"source":["def assert_distribution(train_data, train1_indices, train2_indices):\n","  c1, c2 = 0, 0\n","  for ix in train1_indices:\n","    if train_data.targets[ix] == 0:\n","      c1 += 1\n","    elif train_data.targets[ix] == 1:\n","      c2 += 1\n","  print(\"Worker 1 Set:-\\n\")\n","  print(\"Label 1 samples = \", c1, \" Label 2 samples = \" , c2)\n","  c1, c2 = 0, 0\n","  for ix in train2_indices:\n","    if train_data.targets[ix] == 0:\n","      c1 += 1\n","    elif train_data.targets[ix] == 1:\n","      c2 += 1\n","  print(\"Worker 1 Set:-\\n\")\n","  print(\"Label 1 samples = \", c1, \" Label 2 samples = \" , c2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2700 1800\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RD_oq9qZuluQ"},"source":["batch_size = 300\n","import random\n","def create_dataloader(train_data, test_data, train1_indices, train2_indices, val_indices, batch_size):\n","  batched_indices = []\n","  no_of_batches = int(len(train1_indices)/batch_size)\n","  for i in range(no_of_batches):\n","    batched_indices.append([j for j in range(batch_size*i, batch_size*(i+1))])\n","  random.shuffle(batched_indices)\n","  train1_batched_indices = np.array([], dtype=np.int32)\n","  train2_batched_indices = np.array([], dtype=np.int32)\n","  for i in range(no_of_batches):\n","    train1_batched_indices = np.append(train1_batched_indices, train1_indices[batched_indices[i]])\n","    train2_batched_indices = np.append(train2_batched_indices, train2_indices[batched_indices[i]])\n","  train1_dataloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = False, sampler = train1_batched_indices)\n","  train2_dataloader = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle = False, sampler = train2_batched_indices)\n","  val_dataloader = torch.utils.data.DataLoader(train_data, batch_size = 1024, shuffle = False, sampler = val_indices)\n","  test_dataloader = torch.utils.data.DataLoader(test_data, batch_size = 1024, shuffle = False, sampler = test_indices)\n","  return train1_dataloader, train2_dataloader, val_dataloader, test_dataloader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gv2n-0InwLG0"},"source":["train1, train2, val, test = create_dataloader(train_data, test_data, train1_indices, train2_indices, val_indices, batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YxWJDniraxGV"},"source":["### Implement Augmentation Function"]},{"cell_type":"markdown","metadata":{"id":"fqFTaytUABl9"},"source":["#### Helper Functions"]},{"cell_type":"code","metadata":{"id":"BjlJ5N52A4H_"},"source":["# augmentation utils\n","class RandomApply(nn.Module):\n","    def __init__(self, fn, p):\n","        super().__init__()\n","        self.fn = fn                 # Transform function to apply\n","        self.p = p                   # Probability of application\n","    def forward(self, x):\n","        if random.random() > self.p:\n","            return x\n","        return self.fn(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvmIZBx6Bo75"},"source":["transform_fn = nn.Sequential(RandomApply(augs.ColorJitter(0.8, 0.8, 0.8, 0.2), p=0.8), \n","                             augs.RandomGrayscale(p=0.3), \n","                             augs.RandomHorizontalFlip(), \n","                             RandomApply(filters.GaussianBlur2d((3, 3), (1.5, 1.5)), p=0.2), \n","                             augs.RandomResizedCrop((32, 32)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b-XPAplIa5C3"},"source":["### Implement Contrastive Loss function"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X80Iy6kUpr_E","executionInfo":{"status":"ok","timestamp":1622044254479,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"2e49e81e-8079-49d1-c3b7-7aa45c15e770"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive/\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sXgGOFCea8LW"},"source":["# queries -> Activation of image, keys -> Activation of Augmented Images\n","def contrastive_loss(queries, keys, temperature = 0.1):\n","    b, device = queries.shape[0], queries.device\n","    logits = queries @ keys.t()\n","    logits = logits - logits.max(dim=-1, keepdim=True).values\n","    logits /= temperature\n","    return F.cross_entropy(logits, torch.arange(b, device=device))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SjTLiy9GxJvs"},"source":["def softXEnt (input, target):\n","    logprobs = torch.nn.functional.log_softmax (input, dim = 1)\n","    return  -(target * logprobs).sum() / input.shape[0]\n","\n","def Contrastive_Loss(x, y, temperature=750.0):\n","  batch_size = x.size()[0]\n","  x = nn.functional.normalize(x, dim=1)\n","  y = nn.functional.normalize(y, dim=1)\n","  LARGE_NUM = 1e9\n","  mask = torch.eye(batch_size)\n","  label = nn.functional.one_hot(torch.arange(0, batch_size), num_classes = 2*batch_size).type(torch.float32)\n","  if torch.cuda.is_available():\n","      mask=mask.cuda()\n","      label=label.cuda()\n","  logits_aa = torch.matmul(x, x.t())/temperature\n","  logits_bb = torch.matmul(y, y.t())/temperature\n","  logits_ab = torch.matmul(x, y.t())/temperature\n","  logits_ba = torch.matmul(y, x.t())/temperature\n","\n","  logits_aa = logits_aa - mask*LARGE_NUM\n","  logits_bb = logits_bb - mask*LARGE_NUM\n","\n","  loss_a = softXEnt(torch.cat((logits_ab, logits_aa), dim=1), label)\n","  loss_b = softXEnt(torch.cat((logits_ba, logits_bb), dim=1), label)\n","\n","  loss = loss_a + loss_b\n","  return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOUwJbJCwhx0"},"source":["class BicontrastiveLoss(nn.Module):\n","  def __init__(self, margin=1.0, temperature = 1.0, lower_bound = 1e-3):\n","    super(BicontrastiveLoss, self).__init__()\n","    self.margin = margin\n","    self.temperature = temperature\n","    self.clip_low = lower_bound\n","\n","  def forward(self, X, Y):\n","    batch_size, hidden_dim = X.shape\n","    x = nn.functional.normalize(X, p=2, dim=1)\n","    y = nn.functional.normalize(Y, p=2, dim=1)\n","    mask = torch.ones((4*batch_size, batch_size))*self.margin\n","    if torch.cuda.is_available():\n","      mask=mask.cuda()\n","    pos_x = torch.matmul(x, x.t())/self.temperature\n","    pos_y = torch.matmul(y, y.t())/self.temperature\n","    neg_xy = torch.matmul(x, y.t())/self.temperature\n","    neg_yx = torch.matmul(y, x.t())/self.temperature\n","    v = torch.cat((pos_x, pos_y, neg_xy, neg_yx), dim=0)\n","    #exp_v = torch.exp(v)\n","    #soft_v = exp_v/torch.sum(exp_v)\n","    soft_v = (v-torch.min(v))/(torch.max(v)-torch.min(v))\n","    #soft_v = torch.clip(soft_v, min=self.clip_low)\n","    mask[:2*batch_size, :] = 2*soft_v[:2*batch_size, :]\n","    loss = torch.sum(-torch.log(mask-soft_v))\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9UuT4aeWmTu","executionInfo":{"status":"ok","timestamp":1622291947280,"user_tz":-330,"elapsed":618,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["x = torch.rand((32, 128, 128), dtype=torch.float32, requires_grad=False)\n","y = torch.rand((32, 128, 128), dtype=torch.float32, requires_grad=False)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFZCMPQoW6QD","executionInfo":{"status":"ok","timestamp":1622292446327,"user_tz":-330,"elapsed":396,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["target1 = torch.round(torch.rand((32), dtype=torch.float32, requires_grad=False)).type(torch.int32)\n","target2 = torch.round(torch.rand((32), dtype=torch.float32, requires_grad=False)).type(torch.int32)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3Zeqrx7W6xO","executionInfo":{"status":"ok","timestamp":1622292353990,"user_tz":-330,"elapsed":343,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["W1 = nn.Sequential(nn.Linear(128*128, 512),\n","                  nn.ReLU(),\n","                  nn.Linear(512, 64)\n",")\n","W2 = nn.Sequential(nn.Linear(128*128, 512),\n","                  nn.ReLU(),\n","                  nn.Linear(512, 64)\n",")\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"1VmfqvbnWZly","executionInfo":{"status":"ok","timestamp":1622292416436,"user_tz":-330,"elapsed":415,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["X = W1(x.view(x.size(0), -1))\n","Y = W1(y.view(y.size(0), -1))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"cFfrUitBW7Jc","executionInfo":{"status":"ok","timestamp":1622292975049,"user_tz":-330,"elapsed":326,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["def distance_loss(X, Y, target1, target2):\n","  s = 0\n","  for ix, t1 in zip(X, target1):\n","    for iy, t2 in zip(Y, target2):\n","      if t1 == t2:\n","        continue\n","      s += torch.square(ix - iy)\n","  loss = 1/torch.sum(s)\n","  return loss"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2-mQnPhXBNH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622292893533,"user_tz":-330,"elapsed":403,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"24154633-1297-46fe-a843-c90dcd4edd9c"},"source":["for n, p in W1.named_parameters():\n","  print(n, p.grad)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0.weight None\n","0.bias None\n","2.weight None\n","2.bias None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"62eZSc_hLMya","executionInfo":{"status":"ok","timestamp":1622292907051,"user_tz":-330,"elapsed":368,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}}},"source":["loss.backward()"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"4fq2nEWjL7gm"},"source":["for n, p in W1.named_parameters():\n","  print(n, p.grad)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUPZ5PPlMV6Q","executionInfo":{"status":"ok","timestamp":1622293426449,"user_tz":-330,"elapsed":18245,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"499ff31d-0cb1-4e02-a424-02cb12f65241"},"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")  "],"execution_count":32,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xx7hOkOhPB9Z","executionInfo":{"status":"ok","timestamp":1622293444290,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"e020dbbd-472f-4510-eb25-b5ae596a1465"},"source":["cd /content/gdrive/Shareddrives/Disk1/InfoPro-Pytorch/Experiments on CIFAR-SVHN-STL10"],"execution_count":33,"outputs":[{"output_type":"stream","text":["/content/gdrive/Shareddrives/Disk1/InfoPro-Pytorch/Experiments on CIFAR-SVHN-STL10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"B6zUhmIHOOcv","executionInfo":{"status":"error","timestamp":1622314438082,"user_tz":-330,"elapsed":2614210,"user":{"displayName":"Deakin Internship2021","photoUrl":"","userId":"10106495198254210078"}},"outputId":"94b61753-d025-4213-e44a-ef26b9f3918d"},"source":["%%shell\n","CUDA_VISIBLE_DEVICES=0 python train_data.py --dataset cifar10 --model resnet --layers 32 --droprate 0.0 --cos_lr --local_module_num 2  --local_loss_mode cross_entropy --aux_net_widen 1 --aux_net_feature_dim 128 --alpha_1 5 --beta_1 1.0 --beta_2 1.0 --ixx_2 0 --ixy_2 0 --gamma_1 1.0 --gamma_2 0.0 --aux_net_config 1c2f "],"execution_count":46,"outputs":[{"output_type":"stream","text":["Storing in ... ./InfoPro_cifar10_resnet32_K_2_/tuning_weights/no_1_aux_net_config_1c2f_local_loss_mode_cross_entropy_aux_net_widen_1.0_aux_net_feature_dim_128_alpha_1_5.0_beta_1_1.0_beta_2_1.0_ixx_2_0.0_ixy_2_0.0_cos_lr__gamma_1_1.0_gamma_2_0.0_single_backpass\n","Files already downloaded and verified\n","Files already downloaded and verified\n","No of samples used (10000,) and unused (0,)\n","No of samples used (2000,) and unused (0,)\n","Worker 1 Set:-\n","Label 1 samples =  2250  Label 2 samples =  2250\n","Worker 2 Set:-\n","Label 1 samples =  2250  Label 2 samples =  2250\n","W1 Epoch: [0][1/9]\tTime 32.461 (32.461)\tLoss 0.7680 (0.7680)\tPrec@1 34.961 (34.961)\t\n","W2 Epoch: [0][1/9]\tTime 32.461 (32.461)\tLoss 0.7122 (0.7122)\tPrec@1 46.680 (46.680)\t\n","W1 Epoch: [0][2/9]\tTime 32.617 (32.539)\tLoss 0.7756 (0.7718)\tPrec@1 31.445 (33.203)\t\n","W2 Epoch: [0][2/9]\tTime 32.617 (32.539)\tLoss 0.7417 (0.7269)\tPrec@1 40.430 (43.555)\t\n","W1 Epoch: [0][3/9]\tTime 31.361 (32.146)\tLoss 0.7352 (0.7596)\tPrec@1 43.359 (36.589)\t\n","W2 Epoch: [0][3/9]\tTime 31.361 (32.146)\tLoss 0.6493 (0.7011)\tPrec@1 62.500 (49.870)\t\n","W1 Epoch: [0][4/9]\tTime 32.195 (32.158)\tLoss 0.7625 (0.7603)\tPrec@1 33.594 (35.840)\t\n","W2 Epoch: [0][4/9]\tTime 32.195 (32.158)\tLoss 0.7208 (0.7060)\tPrec@1 38.281 (46.973)\t\n","W1 Epoch: [0][5/9]\tTime 31.579 (32.042)\tLoss 0.7603 (0.7603)\tPrec@1 32.227 (35.117)\t\n","W2 Epoch: [0][5/9]\tTime 31.579 (32.042)\tLoss 0.6772 (0.7002)\tPrec@1 54.297 (48.438)\t\n","W1 Epoch: [0][6/9]\tTime 32.642 (32.142)\tLoss 0.7330 (0.7558)\tPrec@1 42.578 (36.361)\t\n","W2 Epoch: [0][6/9]\tTime 32.642 (32.142)\tLoss 0.6608 (0.6937)\tPrec@1 67.578 (51.628)\t\n","W1 Epoch: [0][7/9]\tTime 32.145 (32.143)\tLoss 0.7286 (0.7519)\tPrec@1 38.086 (36.607)\t\n","W2 Epoch: [0][7/9]\tTime 32.145 (32.143)\tLoss 0.6884 (0.6929)\tPrec@1 59.766 (52.790)\t\n","W1 Epoch: [0][8/9]\tTime 32.685 (32.211)\tLoss 0.7163 (0.7474)\tPrec@1 40.820 (37.134)\t\n","W2 Epoch: [0][8/9]\tTime 32.685 (32.211)\tLoss 0.6923 (0.6928)\tPrec@1 57.031 (53.320)\t\n","W1 Epoch: [0][9/9]\tTime 24.421 (31.345)\tLoss 0.7149 (0.7445)\tPrec@1 42.822 (37.644)\t\n","W2 Epoch: [0][9/9]\tTime 24.421 (31.345)\tLoss 0.6980 (0.6933)\tPrec@1 54.455 (53.422)\t\n","W1 Val: [0][1/1]\tTime 8.890 (8.890)\tLoss 0.7232 (0.7232)\tPrec@1 47.700 (47.700)\t\n","W2 Val: [0][1/1]\tTime 8.890 (8.890)\tLoss 0.6728 (0.6728)\tPrec@1 53.800 (53.800)\t\n","Best Prec 1:  47.70000076293945\n","Best Prec 2:  53.79999923706055\n","Best avg accuracy:  50.75\n","W1 Epoch: [1][1/9]\tTime 35.008 (35.008)\tLoss 0.7151 (0.7151)\tPrec@1 43.164 (43.164)\t\n","W2 Epoch: [1][1/9]\tTime 35.008 (35.008)\tLoss 0.6591 (0.6591)\tPrec@1 67.188 (67.188)\t\n","W1 Epoch: [1][2/9]\tTime 32.620 (33.814)\tLoss 0.7223 (0.7187)\tPrec@1 38.086 (40.625)\t\n","W2 Epoch: [1][2/9]\tTime 32.620 (33.814)\tLoss 0.6689 (0.6640)\tPrec@1 69.922 (68.555)\t\n","W1 Epoch: [1][3/9]\tTime 32.752 (33.460)\tLoss 0.6931 (0.7101)\tPrec@1 56.055 (45.768)\t\n","W2 Epoch: [1][3/9]\tTime 32.752 (33.460)\tLoss 0.6904 (0.6728)\tPrec@1 58.984 (65.365)\t\n","W1 Epoch: [1][4/9]\tTime 36.124 (34.126)\tLoss 0.7346 (0.7162)\tPrec@1 34.766 (43.018)\t\n","W2 Epoch: [1][4/9]\tTime 36.124 (34.126)\tLoss 0.6473 (0.6664)\tPrec@1 70.703 (66.699)\t\n","W1 Epoch: [1][5/9]\tTime 32.880 (33.877)\tLoss 0.7270 (0.7184)\tPrec@1 36.914 (41.797)\t\n","W2 Epoch: [1][5/9]\tTime 32.880 (33.877)\tLoss 0.6381 (0.6608)\tPrec@1 71.094 (67.578)\t\n","W1 Epoch: [1][6/9]\tTime 41.187 (35.095)\tLoss 0.7018 (0.7156)\tPrec@1 49.023 (43.001)\t\n","W2 Epoch: [1][6/9]\tTime 41.187 (35.095)\tLoss 0.6915 (0.6659)\tPrec@1 62.500 (66.732)\t\n","W1 Epoch: [1][7/9]\tTime 32.157 (34.676)\tLoss 0.6987 (0.7132)\tPrec@1 43.750 (43.108)\t\n","W2 Epoch: [1][7/9]\tTime 32.157 (34.676)\tLoss 0.7051 (0.6715)\tPrec@1 64.648 (66.434)\t\n","W1 Epoch: [1][8/9]\tTime 31.806 (34.317)\tLoss 0.7073 (0.7125)\tPrec@1 42.578 (43.042)\t\n","W2 Epoch: [1][8/9]\tTime 31.806 (34.317)\tLoss 0.6839 (0.6730)\tPrec@1 66.406 (66.431)\t\n","W1 Epoch: [1][9/9]\tTime 24.034 (33.174)\tLoss 0.6937 (0.7108)\tPrec@1 46.782 (43.378)\t\n","W2 Epoch: [1][9/9]\tTime 24.034 (33.174)\tLoss 0.6886 (0.6744)\tPrec@1 65.347 (66.333)\t\n","W1 Val: [1][1/1]\tTime 8.562 (8.562)\tLoss 0.7607 (0.7607)\tPrec@1 50.300 (50.300)\t\n","W2 Val: [1][1/1]\tTime 8.562 (8.562)\tLoss 0.6750 (0.6750)\tPrec@1 62.700 (62.700)\t\n","Best Prec 1:  50.29999923706055\n","Best Prec 2:  62.70000076293945\n","Best avg accuracy:  56.5\n","W1 Epoch: [2][1/9]\tTime 33.193 (33.193)\tLoss 0.6966 (0.6966)\tPrec@1 55.273 (55.273)\t\n","W2 Epoch: [2][1/9]\tTime 33.193 (33.193)\tLoss 0.6717 (0.6717)\tPrec@1 55.273 (55.273)\t\n","W1 Epoch: [2][2/9]\tTime 31.803 (32.498)\tLoss 0.7018 (0.6992)\tPrec@1 52.734 (54.004)\t\n","W2 Epoch: [2][2/9]\tTime 31.803 (32.498)\tLoss 0.7014 (0.6865)\tPrec@1 50.000 (52.637)\t\n","W1 Epoch: [2][3/9]\tTime 31.441 (32.146)\tLoss 0.6921 (0.6968)\tPrec@1 51.562 (53.190)\t\n","W2 Epoch: [2][3/9]\tTime 31.441 (32.146)\tLoss 0.6530 (0.6754)\tPrec@1 63.672 (56.315)\t\n","W1 Epoch: [2][4/9]\tTime 32.195 (32.158)\tLoss 0.6959 (0.6966)\tPrec@1 54.492 (53.516)\t\n","W2 Epoch: [2][4/9]\tTime 32.195 (32.158)\tLoss 0.7198 (0.6865)\tPrec@1 40.625 (52.393)\t\n","W1 Epoch: [2][5/9]\tTime 31.483 (32.023)\tLoss 0.6887 (0.6950)\tPrec@1 60.156 (54.844)\t\n","W2 Epoch: [2][5/9]\tTime 31.483 (32.023)\tLoss 0.6965 (0.6885)\tPrec@1 45.117 (50.938)\t\n","W1 Epoch: [2][6/9]\tTime 31.463 (31.930)\tLoss 0.6951 (0.6950)\tPrec@1 48.438 (53.776)\t\n","W2 Epoch: [2][6/9]\tTime 31.463 (31.930)\tLoss 0.6561 (0.6831)\tPrec@1 60.352 (52.507)\t\n","W1 Epoch: [2][7/9]\tTime 31.226 (31.829)\tLoss 0.6990 (0.6956)\tPrec@1 46.680 (52.762)\t\n","W2 Epoch: [2][7/9]\tTime 31.226 (31.829)\tLoss 0.6539 (0.6789)\tPrec@1 62.305 (53.906)\t\n","W1 Epoch: [2][8/9]\tTime 31.429 (31.779)\tLoss 0.6934 (0.6953)\tPrec@1 45.703 (51.880)\t\n","W2 Epoch: [2][8/9]\tTime 31.429 (31.779)\tLoss 0.6395 (0.6740)\tPrec@1 65.430 (55.347)\t\n","W1 Epoch: [2][9/9]\tTime 23.472 (30.856)\tLoss 0.6874 (0.6946)\tPrec@1 51.238 (51.822)\t\n","W2 Epoch: [2][9/9]\tTime 23.472 (30.856)\tLoss 0.6517 (0.6720)\tPrec@1 63.614 (56.089)\t\n","W1 Val: [2][1/1]\tTime 8.756 (8.756)\tLoss 0.6635 (0.6635)\tPrec@1 61.100 (61.100)\t\n","W2 Val: [2][1/1]\tTime 8.756 (8.756)\tLoss 0.6606 (0.6606)\tPrec@1 57.200 (57.200)\t\n","Best Prec 1:  61.10000228881836\n","Best Prec 2:  62.70000076293945\n","Best avg accuracy:  61.900001525878906\n","W1 Epoch: [3][1/9]\tTime 35.274 (35.274)\tLoss 0.6719 (0.6719)\tPrec@1 62.695 (62.695)\t\n","W2 Epoch: [3][1/9]\tTime 35.274 (35.274)\tLoss 0.6754 (0.6754)\tPrec@1 50.586 (50.586)\t\n","W1 Epoch: [3][2/9]\tTime 35.608 (35.441)\tLoss 0.6727 (0.6723)\tPrec@1 62.891 (62.793)\t\n","W2 Epoch: [3][2/9]\tTime 35.608 (35.441)\tLoss 0.7028 (0.6891)\tPrec@1 44.141 (47.363)\t\n","W1 Epoch: [3][3/9]\tTime 35.944 (35.609)\tLoss 0.6776 (0.6741)\tPrec@1 58.398 (61.328)\t\n","W2 Epoch: [3][3/9]\tTime 35.944 (35.609)\tLoss 0.6394 (0.6726)\tPrec@1 63.672 (52.799)\t\n","W1 Epoch: [3][4/9]\tTime 34.220 (35.261)\tLoss 0.6736 (0.6739)\tPrec@1 65.234 (62.305)\t\n","W2 Epoch: [3][4/9]\tTime 34.220 (35.261)\tLoss 0.7102 (0.6820)\tPrec@1 42.578 (50.244)\t\n","W1 Epoch: [3][5/9]\tTime 31.521 (34.513)\tLoss 0.6639 (0.6719)\tPrec@1 70.898 (64.023)\t\n","W2 Epoch: [3][5/9]\tTime 31.521 (34.513)\tLoss 0.6864 (0.6829)\tPrec@1 48.828 (49.961)\t\n","W1 Epoch: [3][6/9]\tTime 38.349 (35.153)\tLoss 0.6735 (0.6722)\tPrec@1 61.133 (63.542)\t\n","W2 Epoch: [3][6/9]\tTime 38.349 (35.153)\tLoss 0.6496 (0.6773)\tPrec@1 63.867 (52.279)\t\n","W1 Epoch: [3][7/9]\tTime 33.445 (34.909)\tLoss 0.6690 (0.6717)\tPrec@1 63.281 (63.504)\t\n","W2 Epoch: [3][7/9]\tTime 33.445 (34.909)\tLoss 0.6532 (0.6739)\tPrec@1 66.406 (54.297)\t\n","W1 Epoch: [3][8/9]\tTime 31.261 (34.453)\tLoss 0.6609 (0.6704)\tPrec@1 66.016 (63.818)\t\n","W2 Epoch: [3][8/9]\tTime 31.261 (34.453)\tLoss 0.6384 (0.6694)\tPrec@1 69.336 (56.177)\t\n","W1 Epoch: [3][9/9]\tTime 23.444 (33.229)\tLoss 0.6545 (0.6690)\tPrec@1 71.782 (64.533)\t\n","W2 Epoch: [3][9/9]\tTime 23.444 (33.229)\tLoss 0.6504 (0.6677)\tPrec@1 68.069 (57.244)\t\n","W1 Val: [3][1/1]\tTime 8.574 (8.574)\tLoss 0.6485 (0.6485)\tPrec@1 68.500 (68.500)\t\n","W2 Val: [3][1/1]\tTime 8.574 (8.574)\tLoss 0.6457 (0.6457)\tPrec@1 66.600 (66.600)\t\n","Best Prec 1:  68.5\n","Best Prec 2:  66.5999984741211\n","Best avg accuracy:  67.54999923706055\n","W1 Epoch: [4][1/9]\tTime 32.800 (32.800)\tLoss 0.6557 (0.6557)\tPrec@1 67.773 (67.773)\t\n","W2 Epoch: [4][1/9]\tTime 32.800 (32.800)\tLoss 0.6532 (0.6532)\tPrec@1 60.547 (60.547)\t\n","W1 Epoch: [4][2/9]\tTime 31.571 (32.185)\tLoss 0.6607 (0.6582)\tPrec@1 64.258 (66.016)\t\n","W2 Epoch: [4][2/9]\tTime 31.571 (32.185)\tLoss 0.6572 (0.6552)\tPrec@1 60.938 (60.742)\t\n","W1 Epoch: [4][3/9]\tTime 31.622 (31.998)\tLoss 0.6443 (0.6536)\tPrec@1 72.070 (68.034)\t\n","W2 Epoch: [4][3/9]\tTime 31.622 (31.998)\tLoss 0.6407 (0.6504)\tPrec@1 68.359 (63.281)\t\n","W1 Epoch: [4][4/9]\tTime 32.073 (32.016)\tLoss 0.6742 (0.6587)\tPrec@1 59.570 (65.918)\t\n","W2 Epoch: [4][4/9]\tTime 32.073 (32.016)\tLoss 0.6600 (0.6528)\tPrec@1 60.156 (62.500)\t\n","W1 Epoch: [4][5/9]\tTime 31.389 (31.891)\tLoss 0.6502 (0.6570)\tPrec@1 68.164 (66.367)\t\n","W2 Epoch: [4][5/9]\tTime 31.389 (31.891)\tLoss 0.6494 (0.6521)\tPrec@1 64.844 (62.969)\t\n","W1 Epoch: [4][6/9]\tTime 31.425 (31.813)\tLoss 0.6381 (0.6539)\tPrec@1 72.266 (67.350)\t\n","W2 Epoch: [4][6/9]\tTime 31.425 (31.813)\tLoss 0.6481 (0.6514)\tPrec@1 69.141 (63.997)\t\n","W1 Epoch: [4][7/9]\tTime 31.270 (31.736)\tLoss 0.6414 (0.6521)\tPrec@1 72.070 (68.025)\t\n","W2 Epoch: [4][7/9]\tTime 31.270 (31.736)\tLoss 0.6574 (0.6523)\tPrec@1 68.359 (64.621)\t\n","W1 Epoch: [4][8/9]\tTime 31.306 (31.682)\tLoss 0.6258 (0.6488)\tPrec@1 75.586 (68.970)\t\n","W2 Epoch: [4][8/9]\tTime 31.306 (31.682)\tLoss 0.6373 (0.6504)\tPrec@1 67.383 (64.966)\t\n","W1 Epoch: [4][9/9]\tTime 23.294 (30.750)\tLoss 0.6212 (0.6463)\tPrec@1 77.970 (69.778)\t\n","W2 Epoch: [4][9/9]\tTime 23.294 (30.750)\tLoss 0.6423 (0.6497)\tPrec@1 69.059 (65.333)\t\n","W1 Val: [4][1/1]\tTime 8.627 (8.627)\tLoss 0.6276 (0.6276)\tPrec@1 72.300 (72.300)\t\n","W2 Val: [4][1/1]\tTime 8.627 (8.627)\tLoss 0.6294 (0.6294)\tPrec@1 70.900 (70.900)\t\n","Best Prec 1:  72.30000305175781\n","Best Prec 2:  70.9000015258789\n","Best avg accuracy:  71.60000228881836\n","W1 Epoch: [5][1/9]\tTime 32.427 (32.427)\tLoss 0.6269 (0.6269)\tPrec@1 73.242 (73.242)\t\n","W2 Epoch: [5][1/9]\tTime 32.427 (32.427)\tLoss 0.6351 (0.6351)\tPrec@1 66.797 (66.797)\t\n","W1 Epoch: [5][2/9]\tTime 31.576 (32.002)\tLoss 0.6352 (0.6311)\tPrec@1 66.797 (70.020)\t\n","W2 Epoch: [5][2/9]\tTime 31.576 (32.002)\tLoss 0.6410 (0.6380)\tPrec@1 67.383 (67.090)\t\n","W1 Epoch: [5][3/9]\tTime 31.477 (31.827)\tLoss 0.6188 (0.6270)\tPrec@1 74.219 (71.419)\t\n","W2 Epoch: [5][3/9]\tTime 31.477 (31.827)\tLoss 0.6408 (0.6390)\tPrec@1 69.141 (67.773)\t\n","W1 Epoch: [5][4/9]\tTime 32.492 (31.993)\tLoss 0.6463 (0.6318)\tPrec@1 67.188 (70.361)\t\n","W2 Epoch: [5][4/9]\tTime 32.492 (31.993)\tLoss 0.6425 (0.6398)\tPrec@1 62.500 (66.455)\t\n","W1 Epoch: [5][5/9]\tTime 31.380 (31.870)\tLoss 0.6272 (0.6309)\tPrec@1 68.945 (70.078)\t\n","W2 Epoch: [5][5/9]\tTime 31.380 (31.870)\tLoss 0.6369 (0.6393)\tPrec@1 66.602 (66.484)\t\n","W1 Epoch: [5][6/9]\tTime 31.329 (31.780)\tLoss 0.6094 (0.6273)\tPrec@1 75.781 (71.029)\t\n","W2 Epoch: [5][6/9]\tTime 31.329 (31.780)\tLoss 0.6313 (0.6379)\tPrec@1 70.898 (67.220)\t\n","W1 Epoch: [5][7/9]\tTime 38.183 (32.695)\tLoss 0.6285 (0.6275)\tPrec@1 74.219 (71.484)\t\n","W2 Epoch: [5][7/9]\tTime 38.183 (32.695)\tLoss 0.6407 (0.6383)\tPrec@1 67.578 (67.271)\t\n","W1 Epoch: [5][8/9]\tTime 34.117 (32.873)\tLoss 0.6046 (0.6246)\tPrec@1 74.805 (71.899)\t\n","W2 Epoch: [5][8/9]\tTime 34.117 (32.873)\tLoss 0.6184 (0.6358)\tPrec@1 73.242 (68.018)\t\n","W1 Epoch: [5][9/9]\tTime 23.800 (31.864)\tLoss 0.6079 (0.6231)\tPrec@1 74.257 (72.111)\t\n","W2 Epoch: [5][9/9]\tTime 23.800 (31.864)\tLoss 0.6159 (0.6340)\tPrec@1 68.564 (68.067)\t\n","W1 Val: [5][1/1]\tTime 8.525 (8.525)\tLoss 0.6038 (0.6038)\tPrec@1 73.600 (73.600)\t\n","W2 Val: [5][1/1]\tTime 8.525 (8.525)\tLoss 0.6195 (0.6195)\tPrec@1 71.300 (71.300)\t\n","Best Prec 1:  73.5999984741211\n","Best Prec 2:  71.30000305175781\n","Best avg accuracy:  72.45000076293945\n","W1 Epoch: [6][1/9]\tTime 32.810 (32.810)\tLoss 0.6081 (0.6081)\tPrec@1 74.023 (74.023)\t\n","W2 Epoch: [6][1/9]\tTime 32.810 (32.810)\tLoss 0.6242 (0.6242)\tPrec@1 67.383 (67.383)\t\n","W1 Epoch: [6][2/9]\tTime 32.026 (32.418)\tLoss 0.6118 (0.6100)\tPrec@1 71.289 (72.656)\t\n","W2 Epoch: [6][2/9]\tTime 32.026 (32.418)\tLoss 0.6326 (0.6284)\tPrec@1 66.016 (66.699)\t\n","W1 Epoch: [6][3/9]\tTime 31.907 (32.248)\tLoss 0.5972 (0.6057)\tPrec@1 74.805 (73.372)\t\n","W2 Epoch: [6][3/9]\tTime 31.907 (32.248)\tLoss 0.6200 (0.6256)\tPrec@1 71.680 (68.359)\t\n","W1 Epoch: [6][4/9]\tTime 33.471 (32.553)\tLoss 0.6452 (0.6156)\tPrec@1 65.625 (71.436)\t\n","W2 Epoch: [6][4/9]\tTime 33.471 (32.553)\tLoss 0.6434 (0.6300)\tPrec@1 61.328 (66.602)\t\n","W1 Epoch: [6][5/9]\tTime 32.361 (32.515)\tLoss 0.5949 (0.6114)\tPrec@1 73.438 (71.836)\t\n","W2 Epoch: [6][5/9]\tTime 32.361 (32.515)\tLoss 0.6255 (0.6291)\tPrec@1 66.602 (66.602)\t\n","W1 Epoch: [6][6/9]\tTime 32.643 (32.536)\tLoss 0.5892 (0.6077)\tPrec@1 75.195 (72.396)\t\n","W2 Epoch: [6][6/9]\tTime 32.643 (32.536)\tLoss 0.6138 (0.6266)\tPrec@1 72.852 (67.643)\t\n","W1 Epoch: [6][7/9]\tTime 31.978 (32.457)\tLoss 0.6048 (0.6073)\tPrec@1 73.828 (72.600)\t\n","W2 Epoch: [6][7/9]\tTime 31.978 (32.457)\tLoss 0.6307 (0.6272)\tPrec@1 68.555 (67.773)\t\n","W1 Epoch: [6][8/9]\tTime 31.943 (32.392)\tLoss 0.5731 (0.6030)\tPrec@1 76.953 (73.145)\t\n","W2 Epoch: [6][8/9]\tTime 31.943 (32.392)\tLoss 0.6032 (0.6242)\tPrec@1 71.875 (68.286)\t\n","W1 Epoch: [6][9/9]\tTime 23.286 (31.381)\tLoss 0.5766 (0.6007)\tPrec@1 73.267 (73.156)\t\n","W2 Epoch: [6][9/9]\tTime 23.286 (31.381)\tLoss 0.6079 (0.6227)\tPrec@1 72.277 (68.644)\t\n","W1 Val: [6][1/1]\tTime 8.553 (8.553)\tLoss 0.5914 (0.5914)\tPrec@1 73.800 (73.800)\t\n","W2 Val: [6][1/1]\tTime 8.553 (8.553)\tLoss 0.6030 (0.6030)\tPrec@1 72.900 (72.900)\t\n","Best Prec 1:  73.80000305175781\n","Best Prec 2:  72.9000015258789\n","Best avg accuracy:  73.35000228881836\n","W1 Epoch: [7][1/9]\tTime 34.926 (34.926)\tLoss 0.5903 (0.5903)\tPrec@1 72.266 (72.266)\t\n","W2 Epoch: [7][1/9]\tTime 34.926 (34.926)\tLoss 0.6133 (0.6133)\tPrec@1 66.016 (66.016)\t\n","W1 Epoch: [7][2/9]\tTime 31.916 (33.421)\tLoss 0.5950 (0.5927)\tPrec@1 73.047 (72.656)\t\n","W2 Epoch: [7][2/9]\tTime 31.916 (33.421)\tLoss 0.6237 (0.6185)\tPrec@1 63.867 (64.941)\t\n","W1 Epoch: [7][3/9]\tTime 31.903 (32.915)\tLoss 0.5755 (0.5869)\tPrec@1 74.023 (73.112)\t\n","W2 Epoch: [7][3/9]\tTime 31.903 (32.915)\tLoss 0.6107 (0.6159)\tPrec@1 70.117 (66.667)\t\n","W1 Epoch: [7][4/9]\tTime 33.011 (32.939)\tLoss 0.6197 (0.5951)\tPrec@1 67.773 (71.777)\t\n","W2 Epoch: [7][4/9]\tTime 33.011 (32.939)\tLoss 0.6363 (0.6210)\tPrec@1 59.961 (64.990)\t\n","W1 Epoch: [7][5/9]\tTime 31.771 (32.705)\tLoss 0.5845 (0.5930)\tPrec@1 72.852 (71.992)\t\n","W2 Epoch: [7][5/9]\tTime 31.771 (32.705)\tLoss 0.6168 (0.6202)\tPrec@1 66.211 (65.234)\t\n","W1 Epoch: [7][6/9]\tTime 31.331 (32.476)\tLoss 0.5786 (0.5906)\tPrec@1 74.805 (72.461)\t\n","W2 Epoch: [7][6/9]\tTime 31.331 (32.476)\tLoss 0.6002 (0.6168)\tPrec@1 74.219 (66.732)\t\n","W1 Epoch: [7][7/9]\tTime 31.243 (32.300)\tLoss 0.5876 (0.5902)\tPrec@1 73.047 (72.545)\t\n","W2 Epoch: [7][7/9]\tTime 31.243 (32.300)\tLoss 0.6229 (0.6177)\tPrec@1 68.164 (66.936)\t\n","W1 Epoch: [7][8/9]\tTime 39.518 (33.202)\tLoss 0.5589 (0.5863)\tPrec@1 73.438 (72.656)\t\n","W2 Epoch: [7][8/9]\tTime 39.518 (33.202)\tLoss 0.5890 (0.6141)\tPrec@1 71.875 (67.554)\t\n","W1 Epoch: [7][9/9]\tTime 28.128 (32.639)\tLoss 0.5341 (0.5816)\tPrec@1 78.713 (73.200)\t\n","W2 Epoch: [7][9/9]\tTime 28.128 (32.639)\tLoss 0.5954 (0.6124)\tPrec@1 72.525 (68.000)\t\n","W1 Val: [7][1/1]\tTime 8.616 (8.616)\tLoss 0.5689 (0.5689)\tPrec@1 74.700 (74.700)\t\n","W2 Val: [7][1/1]\tTime 8.616 (8.616)\tLoss 0.6015 (0.6015)\tPrec@1 70.300 (70.300)\t\n","Best Prec 1:  74.70000457763672\n","Best Prec 2:  72.9000015258789\n","Best avg accuracy:  73.80000305175781\n","W1 Epoch: [8][1/9]\tTime 33.285 (33.285)\tLoss 0.5642 (0.5642)\tPrec@1 74.219 (74.219)\t\n","W2 Epoch: [8][1/9]\tTime 33.285 (33.285)\tLoss 0.6056 (0.6056)\tPrec@1 67.773 (67.773)\t\n","W1 Epoch: [8][2/9]\tTime 32.239 (32.762)\tLoss 0.5821 (0.5731)\tPrec@1 73.047 (73.633)\t\n","W2 Epoch: [8][2/9]\tTime 32.239 (32.762)\tLoss 0.6145 (0.6100)\tPrec@1 65.430 (66.602)\t\n","W1 Epoch: [8][3/9]\tTime 31.934 (32.486)\tLoss 0.5581 (0.5681)\tPrec@1 72.852 (73.372)\t\n","W2 Epoch: [8][3/9]\tTime 31.934 (32.486)\tLoss 0.6002 (0.6068)\tPrec@1 72.070 (68.424)\t\n","W1 Epoch: [8][4/9]\tTime 32.471 (32.482)\tLoss 0.6188 (0.5808)\tPrec@1 69.336 (72.363)\t\n","W2 Epoch: [8][4/9]\tTime 32.471 (32.482)\tLoss 0.6247 (0.6113)\tPrec@1 61.914 (66.797)\t\n","W1 Epoch: [8][5/9]\tTime 33.589 (32.704)\tLoss 0.5659 (0.5778)\tPrec@1 74.414 (72.773)\t\n","W2 Epoch: [8][5/9]\tTime 33.589 (32.704)\tLoss 0.6088 (0.6108)\tPrec@1 64.844 (66.406)\t\n","W1 Epoch: [8][6/9]\tTime 36.384 (33.317)\tLoss 0.5706 (0.5766)\tPrec@1 72.461 (72.721)\t\n","W2 Epoch: [8][6/9]\tTime 36.384 (33.317)\tLoss 0.5871 (0.6068)\tPrec@1 74.219 (67.708)\t\n","Traceback (most recent call last):\n","  File \"train_data.py\", line 823, in <module>\n","    main()\n","  File \"train_data.py\", line 442, in main\n","    chunk2_loss = train(train_loader1, train_loader2, model1, model2, optimizer1, optimizer2, epoch)\n","  File \"train_data.py\", line 606, in train\n","    contra_loss_chunk1 = args.gamma_1*distance_loss(hidden1, hidden2, target1, target2)\n","  File \"/content/gdrive/Shareddrives/Disk1/InfoPro-Pytorch/Experiments on CIFAR-SVHN-STL10/networks/losses.py\", line 44, in distance_loss\n","    s += torch.square(ix - iy)\n","KeyboardInterrupt\n"],"name":"stdout"},{"output_type":"error","ename":"CalledProcessError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-aa90d94ba650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CUDA_VISIBLE_DEVICES=0 python train_data.py --dataset cifar10 --model resnet --layers 32 --droprate 0.0 --cos_lr --local_module_num 2  --local_loss_mode cross_entropy --aux_net_widen 1 --aux_net_feature_dim 128 --alpha_1 5 --beta_1 1.0 --beta_2 1.0 --ixx_2 0 --ixy_2 0 --gamma_1 1.0 --gamma_2 0.0 --aux_net_config 1c2f '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m       raise subprocess.CalledProcessError(\n\u001b[0;32m--> 139\u001b[0;31m           returncode=self.returncode, cmd=self.args, output=self.output)\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_repr_pretty_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCalledProcessError\u001b[0m: Command 'CUDA_VISIBLE_DEVICES=0 python train_data.py --dataset cifar10 --model resnet --layers 32 --droprate 0.0 --cos_lr --local_module_num 2  --local_loss_mode cross_entropy --aux_net_widen 1 --aux_net_feature_dim 128 --alpha_1 5 --beta_1 1.0 --beta_2 1.0 --ixx_2 0 --ixy_2 0 --gamma_1 1.0 --gamma_2 0.0 --aux_net_config 1c2f ' returned non-zero exit status 1."]}]},{"cell_type":"code","metadata":{"id":"mE3LEMctT5K3"},"source":[""],"execution_count":null,"outputs":[]}]}